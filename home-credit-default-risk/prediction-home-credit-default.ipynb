{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by [SmirkyGraphs](http://smirkygraphs.github.io/). Code: [GitHub](https://github.com/SmirkyGraphs/Python-Notebooks). Source: [Kaggle](https://www.kaggle.com/c/home-credit-default-risk/data).\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Application Train/Test\n",
    "\n",
    "train = pd.read_csv('./input/application_train.csv')\n",
    "test = pd.read_csv('./input/application_test.csv')\n",
    "\n",
    "features = pd.concat([train, test], keys=['train', 'test'], sort=False)\n",
    "\n",
    "features = features.replace('XNA', np.nan)\n",
    "features = features.replace('XAP', np.nan)\n",
    "\n",
    "# Encoding Categories\n",
    "name_contract_type = pd.get_dummies(features.NAME_CONTRACT_TYPE, prefix='name_contract_type')\n",
    "code_gender = pd.get_dummies(features.CODE_GENDER, prefix='gender')\n",
    "flag_own_car = pd.get_dummies(features.FLAG_OWN_CAR, prefix='own_car')\n",
    "flag_own_realty = pd.get_dummies(features.FLAG_OWN_REALTY, prefix='own_realty')\n",
    "name_type_suite = pd.get_dummies(features.NAME_TYPE_SUITE, prefix='type_suite')\n",
    "name_income_type = pd.get_dummies(features.NAME_INCOME_TYPE, prefix='income_type')\n",
    "name_education_type = pd.get_dummies(features.NAME_EDUCATION_TYPE, prefix='education_type')\n",
    "name_family_status = pd.get_dummies(features.NAME_FAMILY_STATUS, prefix='family_status')\n",
    "name_housing_type = pd.get_dummies(features.NAME_HOUSING_TYPE, prefix='housing_type')\n",
    "occupation_type = pd.get_dummies(features.OCCUPATION_TYPE, prefix='occupation_type')\n",
    "weekday_appr_process_start = pd.get_dummies(features.WEEKDAY_APPR_PROCESS_START, prefix='weekday_appr_process')\n",
    "organization_type = pd.get_dummies(features.ORGANIZATION_TYPE, prefix='org_type')\n",
    "fondkapremont_mode = pd.get_dummies(features.FONDKAPREMONT_MODE, prefix='fondkapremont_mode')\n",
    "housetype_mode = pd.get_dummies(features.HOUSETYPE_MODE, prefix='housetype_mode')\n",
    "wallsmaterial_mode = pd.get_dummies(features.WALLSMATERIAL_MODE, prefix='wallsmaterial_mode')\n",
    "emergencystate_mode = pd.get_dummies(features.EMERGENCYSTATE_MODE, prefix='emergencystate_mode')\n",
    "\n",
    "\n",
    "cols = ['NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'NAME_TYPE_SUITE', \n",
    "        'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE',\n",
    "        'OCCUPATION_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE',\n",
    "        'HOUSETYPE_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE']\n",
    "\n",
    "features = features.drop(columns=cols)\n",
    "\n",
    "features_final = pd.concat([features, name_contract_type, code_gender, flag_own_car, flag_own_realty,\n",
    "                           name_type_suite, name_income_type, name_education_type, name_family_status,\n",
    "                           name_housing_type, occupation_type, weekday_appr_process_start,\n",
    "                           organization_type, fondkapremont_mode, housetype_mode,\n",
    "                           wallsmaterial_mode, emergencystate_mode], axis=1)\n",
    "\n",
    "features_final = features_final.reset_index()\n",
    "features_final = features_final.drop(columns='level_1')\n",
    "features_final = features_final.rename(columns={'level_0' : 'set'})\n",
    "\n",
    "features_final['DAYS_EMPLOYED'] = features_final['DAYS_EMPLOYED'].replace(365243, -999999)\n",
    "features_final = features_final.replace('XNA', np.nan)\n",
    "\n",
    "del [name_contract_type, code_gender, flag_own_car, flag_own_realty, name_type_suite, name_income_type, name_education_type, \n",
    "name_family_status, name_housing_type, occupation_type, weekday_appr_process_start, organization_type, fondkapremont_mode,\n",
    "housetype_mode, wallsmaterial_mode, emergencystate_mode]\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bureau Balance\n",
    "\n",
    "bureau_balance = pd.read_csv('./input/bureau_balance.csv')\n",
    "bureau_balance = pd.get_dummies(bureau_balance, prefix='status')\n",
    "\n",
    "\n",
    "count = bureau_balance[['SK_ID_BUREAU', 'MONTHS_BALANCE']].groupby('SK_ID_BUREAU').count()\n",
    "bureau_balance['months_count'] = bureau_balance['SK_ID_BUREAU'].map(count['MONTHS_BALANCE'])\n",
    "bureau_bal_final = bureau_balance.groupby('SK_ID_BUREAU').mean()\n",
    "\n",
    "del bureau_balance\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bureau\n",
    "\n",
    "bureau = pd.read_csv('./input/bureau.csv')\n",
    "\n",
    "credit_active = pd.get_dummies(bureau.CREDIT_ACTIVE, prefix='cred_active')\n",
    "credit_currency = pd.get_dummies(bureau.CREDIT_CURRENCY, prefix='cred_curr')\n",
    "credit_type = pd.get_dummies(bureau.CREDIT_TYPE, prefix='cred_type')\n",
    "\n",
    "cols = ['CREDIT_ACTIVE', 'CREDIT_CURRENCY', 'CREDIT_TYPE']\n",
    "bureau = bureau.drop(columns=cols)\n",
    "\n",
    "buro_final = pd.concat([bureau, credit_active, credit_currency, credit_type], axis=1)\n",
    "\n",
    "bureau_per_loan = buro_final[['SK_ID_CURR', 'SK_ID_BUREAU']].groupby('SK_ID_CURR').count()\n",
    "buro_final['bureau_per_loan_count'] = buro_final['SK_ID_CURR'].map(bureau_per_loan['SK_ID_BUREAU'])\n",
    "\n",
    "del credit_active, credit_currency, credit_type, bureau\n",
    "gc.collect()\n",
    "\n",
    "buro_final = buro_final.merge(right=bureau_bal_final, how='left', on='SK_ID_BUREAU')\n",
    "\n",
    "buro_final = buro_final.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "del bureau_bal_final\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Credit Card Balance\n",
    "\n",
    "credit_card_bal = pd.read_csv('./input/credit_card_balance.csv')\n",
    "credit_card_bal = pd.get_dummies(credit_card_bal, prefix='cc_name_contract')\n",
    "\n",
    "num_prev_loan = credit_card_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "credit_card_bal['cc_prev_count'] = credit_card_bal['SK_ID_CURR'].map(num_prev_loan['SK_ID_PREV'])\n",
    "\n",
    "credit_card_final = credit_card_bal.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "del credit_card_bal\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Installments Payments\n",
    "\n",
    "installments_payments = pd.read_csv('./input/installments_payments.csv')\n",
    "\n",
    "num_prev_loan = installments_payments[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "installments_payments['install_count'] = installments_payments['SK_ID_CURR'].map(num_prev_loan['SK_ID_PREV'])\n",
    "\n",
    "installments_final = installments_payments.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "del installments_payments\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS Cash Balance\n",
    "\n",
    "pos_cash_bal = pd.read_csv('./input/POS_CASH_balance.csv')\n",
    "\n",
    "pos_cash_bal = pos_cash_bal.replace('XNA', np.nan)\n",
    "pos_cash_bal = pos_cash_bal.replace('XAP', np.nan)\n",
    "\n",
    "pos_cash_bal = pd.get_dummies(pos_cash_bal, prefix='pos_name_contract')\n",
    "\n",
    "num_prev_loan = pos_cash_bal[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "pos_cash_bal['pos_prev_count'] = pos_cash_bal['SK_ID_CURR'].map(num_prev_loan['SK_ID_PREV'])\n",
    "\n",
    "pos_cash_final = pos_cash_bal.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "del pos_cash_bal\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "161"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previous Application\n",
    "\n",
    "prev_app = pd.read_csv('./input/previous_application.csv')\n",
    "\n",
    "prev_app = prev_app.replace('XNA', np.nan)\n",
    "\n",
    "prev_dumm = pd.DataFrame()\n",
    "\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_CONTRACT_TYPE, prefix='name_contract_type')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.WEEKDAY_APPR_PROCESS_START, prefix='weekday_appr_start')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.FLAG_LAST_APPL_PER_CONTRACT, prefix='flag_last_appl')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_CASH_LOAN_PURPOSE, prefix='cash_purpose')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_CONTRACT_STATUS, prefix='contract_status')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_PAYMENT_TYPE, prefix='payment_type')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.CODE_REJECT_REASON, prefix='reject_reason')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_TYPE_SUITE, prefix='type_suite')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_CLIENT_TYPE, prefix='client_type')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_GOODS_CATEGORY, prefix='goods_cat')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_PORTFOLIO, prefix='portfolio')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_PRODUCT_TYPE, prefix='product_type')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.CHANNEL_TYPE, prefix='channel_type')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_SELLER_INDUSTRY, prefix='seller_indust')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.NAME_YIELD_GROUP, prefix='yield_group')], axis=1)\n",
    "prev_dumm = pd.concat([prev_dumm, pd.get_dummies(prev_app.PRODUCT_COMBINATION, prefix='product_comb')], axis=1)\n",
    "\n",
    "\n",
    "cols = ['NAME_CONTRACT_TYPE', 'WEEKDAY_APPR_PROCESS_START', 'FLAG_LAST_APPL_PER_CONTRACT', 'NAME_CASH_LOAN_PURPOSE',\n",
    "        'NAME_CONTRACT_STATUS', 'NAME_PAYMENT_TYPE', 'CODE_REJECT_REASON', 'NAME_TYPE_SUITE', 'NAME_CLIENT_TYPE', \n",
    "        'NAME_GOODS_CATEGORY', 'NAME_PORTFOLIO', 'NAME_PRODUCT_TYPE', 'CHANNEL_TYPE', 'NAME_SELLER_INDUSTRY',\n",
    "        'NAME_YIELD_GROUP', 'PRODUCT_COMBINATION']\n",
    "\n",
    "prev_app = pd.concat([prev_app, prev_dumm], axis=1)\n",
    "\n",
    "prev_app = prev_app.drop(columns=cols)\n",
    "\n",
    "num_prev_loan = prev_app[['SK_ID_CURR', 'SK_ID_PREV']].groupby('SK_ID_CURR').count()\n",
    "prev_app['prev_count'] = prev_app['SK_ID_CURR'].map(num_prev_loan['SK_ID_PREV'])\n",
    "\n",
    "prev_final = prev_app.groupby('SK_ID_CURR').mean()\n",
    "\n",
    "del prev_dumm, prev_app\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Files\n",
    "\n",
    "final_data = features_final.merge(right=buro_final, how='left', on='SK_ID_CURR')\n",
    "final_data = final_data.merge(right=prev_final, how='left', on='SK_ID_CURR')\n",
    "final_data = final_data.merge(right=pos_cash_final, how='left', on='SK_ID_CURR')\n",
    "final_data = final_data.merge(right=credit_card_final, how='left', on='SK_ID_CURR')\n",
    "final_data = final_data.merge(right=installments_final, how='left', on='SK_ID_CURR')\n",
    "\n",
    "cols = ['SK_ID_PREV_x', 'SK_ID_PREV_y', 'SK_ID_BUREAU']\n",
    "\n",
    "final_data = final_data.drop(columns=cols)\n",
    "\n",
    "del features_final, buro_final, prev_final, pos_cash_final, credit_card_final, installments_final\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split Train/Test\n",
    "\n",
    "train = final_data.loc[final_data['set'] == 'train']\n",
    "test = final_data.loc[final_data['set'] == 'test']\n",
    "\n",
    "train = train.drop(['set'], axis=1)\n",
    "\n",
    "test = test.drop(['set'], axis=1)\n",
    "test = test.drop(['TARGET'], axis=1)\n",
    "\n",
    "del final_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['TARGET'], axis=1)\n",
    "y = train.TARGET\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=4,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier(\n",
    "            n_estimators=4000,\n",
    "            learning_rate=0.03,\n",
    "            num_leaves=30,\n",
    "            colsample_bytree=.8,\n",
    "            subsample=.9,\n",
    "            max_depth=7,\n",
    "            reg_alpha=.1,\n",
    "            reg_lambda=.1,\n",
    "            min_split_gain=.01,\n",
    "            min_child_weight=2,\n",
    "            silent=-1,\n",
    "            verbose=-1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's auc: 0.783931\tvalid_1's auc: 0.760559\n",
      "[200]\ttraining's auc: 0.806841\tvalid_1's auc: 0.771149\n",
      "[300]\ttraining's auc: 0.821768\tvalid_1's auc: 0.774805\n",
      "[400]\ttraining's auc: 0.834434\tvalid_1's auc: 0.776295\n",
      "[500]\ttraining's auc: 0.845971\tvalid_1's auc: 0.776932\n",
      "[600]\ttraining's auc: 0.856261\tvalid_1's auc: 0.77719\n",
      "[700]\ttraining's auc: 0.865363\tvalid_1's auc: 0.777286\n",
      "[800]\ttraining's auc: 0.874226\tvalid_1's auc: 0.777523\n",
      "[900]\ttraining's auc: 0.882001\tvalid_1's auc: 0.777479\n",
      "Early stopping, best iteration is:\n",
      "[819]\ttraining's auc: 0.875897\tvalid_1's auc: 0.777598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=0.8,\n",
       "        importance_type='split', learning_rate=0.03, max_depth=7,\n",
       "        min_child_samples=20, min_child_weight=2, min_split_gain=0.01,\n",
       "        n_estimators=4000, n_jobs=-1, num_leaves=30, objective=None,\n",
       "        random_state=None, reg_alpha=0.1, reg_lambda=0.1, silent=-1,\n",
       "        subsample=0.9, subsample_for_bin=200000, subsample_freq=0,\n",
       "        verbose=-1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, \n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)], \n",
    "        eval_metric='auc', verbose=100, early_stopping_rounds=100\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "                n_estimators=4000,\n",
    "                learning_rate=0.03,\n",
    "                n_jobs=-1, \n",
    "                nthread=-1 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.688411\tvalidation_1-auc:0.683621\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 100 rounds.\n",
      "[100]\tvalidation_0-auc:0.737058\tvalidation_1-auc:0.73027\n",
      "[200]\tvalidation_0-auc:0.764864\tvalidation_1-auc:0.753471\n",
      "[300]\tvalidation_0-auc:0.777168\tvalidation_1-auc:0.76255\n",
      "[400]\tvalidation_0-auc:0.784437\tvalidation_1-auc:0.76709\n",
      "[500]\tvalidation_0-auc:0.789378\tvalidation_1-auc:0.769664\n",
      "[600]\tvalidation_0-auc:0.793224\tvalidation_1-auc:0.771252\n",
      "[700]\tvalidation_0-auc:0.796545\tvalidation_1-auc:0.772734\n",
      "[800]\tvalidation_0-auc:0.799528\tvalidation_1-auc:0.773678\n",
      "[900]\tvalidation_0-auc:0.802359\tvalidation_1-auc:0.774525\n",
      "[1000]\tvalidation_0-auc:0.804939\tvalidation_1-auc:0.775189\n",
      "[1100]\tvalidation_0-auc:0.807429\tvalidation_1-auc:0.775831\n",
      "[1200]\tvalidation_0-auc:0.809751\tvalidation_1-auc:0.776371\n",
      "[1300]\tvalidation_0-auc:0.812046\tvalidation_1-auc:0.776712\n",
      "[1400]\tvalidation_0-auc:0.814172\tvalidation_1-auc:0.777097\n",
      "[1500]\tvalidation_0-auc:0.816074\tvalidation_1-auc:0.777355\n",
      "[1600]\tvalidation_0-auc:0.818133\tvalidation_1-auc:0.77769\n",
      "[1700]\tvalidation_0-auc:0.820005\tvalidation_1-auc:0.777868\n",
      "[1800]\tvalidation_0-auc:0.821764\tvalidation_1-auc:0.778007\n",
      "[1900]\tvalidation_0-auc:0.823649\tvalidation_1-auc:0.778062\n",
      "[2000]\tvalidation_0-auc:0.825222\tvalidation_1-auc:0.778147\n",
      "[2100]\tvalidation_0-auc:0.826838\tvalidation_1-auc:0.778276\n",
      "[2200]\tvalidation_0-auc:0.828373\tvalidation_1-auc:0.778281\n",
      "Stopping. Best iteration:\n",
      "[2142]\tvalidation_0-auc:0.827491\tvalidation_1-auc:0.77829\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.03, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=4000,\n",
       "       n_jobs=-1, nthread=-1, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train, y_train, \n",
    "        eval_set = [(X_train, y_train), (X_test, y_test)], \n",
    "        eval_metric='auc', verbose=100, early_stopping_rounds=100\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_results = clf.predict_proba(test, num_iteration=clf.best_iteration_)[:,1]\n",
    "xgb_results = xgb_model.predict_proba(test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = xgb_results*0.70 + lgb_results*0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'SK_ID_CURR': test.SK_ID_CURR, 'TARGET': predictions}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submissions.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
